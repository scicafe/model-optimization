# Model Optimization
An Exploration of model optimization using the TensorFlow Model Optimization Toolkit (TFMOT) and TensorFlow Lite (TFLite)


## Released Blogs

#### Quantization Aware Training using TFMOT
Topics covered:
- Introduce TFMOT
- Introduce QAT
- Show example of QAT
- Post training quantization
- Introduce TFLite
- Quantize model
- Compare Performance
- Save models and compare performance

[Blog](https://sci.cafe/quantization-1) | [Colab Notebook](https://colab.research.google.com/drive/1-xiwp2s1Oir8sNh-Utnj60yAtpjwDaUr?usp=sharing) | [Trained Models](https://github.com/scicafe/model-optimization/releases/tag/v1.0) | [Code](/part_1/)

## Future Blogs
- INT8 Inference and Model Latency
    - Measure the latency of models trained in previous blog
    - Introduction to EdgeTPU and Accelerator
    - Convert model and run it on EdgeTPU
- Model Pruning using TFMOT
    - Introduce TFMOT's Model Pruning API
    - Prune Models
    - Exploration of performance
- Choose layers to quantize
    - An NAS approach to chosing which layers to quantize
